
---
title: "Practical Machine Learning Course Assignment"
author: "Matthew Mariano"
date: "January 24, 2015"
output: html_document
---

    
##Introduction

The purpose of this project is to model training data and use that model to make accurate predictions of test data.
The data for this project was generated by having participants perform a dumbell excercise in several different ways and capturing the readings from accelerometers on the participant and on the dumbell. The different ways the dumbell is lifted are labelled A through E and are represented in the column classe in the training data.
 In addition to predicting the 20 test cases, model accuracy, cross validation and out of sample error will be discussed.

##Assignment Setup

The training data is available here.
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>
It contains 19622 observations with 160 variables.

The testing data is available here.
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>
It contains 20 observations in 160 variables.

##Preprocessing the Data

Preprocessing the data is important for an accurate model.
The file preProcessing.R contains several functions with some documentation showing how to determine the columns to remove from the testing and training data sets.
The basic steps for preprocessing the data follow:
1. load the training and testing data; use the option na.strings = c('', 'NA','#DIV/0!'))
2. remove any columns containg NA. 
3. remove non numeric columns like the timestamps
4. remove the column for the trial number

This leaves 52 predictors and the response variable, classe.

##Choosing a Model

I chose random forest for the following reasons.
1. it provides logistic regression on multiple labels(here we have five, A through E)
2. In R, cross validation is provided 
3. it is very accurate

Cross validation is done using a trainControl in the train method.
The number of folds chosen is 3. Although this is small choosing a larger size does not change the prediction on the test set.

##Start of the Main Processing

1. load the required libraries
2. set a seed for reproducible results
3. read the training and test sets
4. create a model using the train function

```{r}
library(caret)
library(ggplot2)

library(randomForest)
source(file="Utils.R")
set.seed(1234)

train <- read.csv("./data/pml-training.csv", header = TRUE, na.strings = c('', 'NA','#DIV/0!'))
test <- read.csv("./data/pml-testing.csv", header = TRUE, na.strings = c('', 'NA','#DIV/0!'))

train2=train[,c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt", 
 "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", "accel_belt_x", "accel_belt_y", 
 "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", "pitch_arm", 
 "yaw_arm", "total_accel_arm", "gyros_arm_x", "gyros_arm_y", "gyros_arm_z", "accel_arm_x", 
 "accel_arm_y", "accel_arm_z", "magnet_arm_x", "magnet_arm_y", "magnet_arm_z", 
 "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", "total_accel_dumbbell", "gyros_dumbbell_x", 
 "gyros_dumbbell_y", "gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", 
 "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", "pitch_forearm", 
 "yaw_forearm", "total_accel_forearm", "gyros_forearm_x", "gyros_forearm_y", "gyros_forearm_z", 
 "accel_forearm_x", "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y", 
 "magnet_forearm_z","classe")]

test2=test[,c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt", 
 "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", "accel_belt_x", "accel_belt_y", 
 "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", "pitch_arm", 
 "yaw_arm", "total_accel_arm", "gyros_arm_x", "gyros_arm_y", "gyros_arm_z", "accel_arm_x", 
 "accel_arm_y", "accel_arm_z", "magnet_arm_x", "magnet_arm_y", "magnet_arm_z", 
 "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", "total_accel_dumbbell", "gyros_dumbbell_x", 
 "gyros_dumbbell_y", "gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", 
 "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", "pitch_forearm", 
 "yaw_forearm", "total_accel_forearm", "gyros_forearm_x", "gyros_forearm_y", "gyros_forearm_z", 
 "accel_forearm_x", "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y", 
 "magnet_forearm_z")]

```
Define a trainControl function for the train function.
This allows cross validation to be specified and the number of folds. 
Verbose just prints a line to the console for processing each fold.
```{r}
#train2=createSample(train2)
tc <- trainControl(method = "cv", number = 3,  verboseIter = TRUE)
model <- train(classe ~ ., data = train2,  method="rf", trControl = tc)
```
print out the model
```{r}
model
```
predict using the model and the test data. then print the predictions.
```{r}
predictions=predict(model$finalModel,newdata=test2)
predictions
pml_write_files(predictions)
```

##Conclusion

The accuracy for the chosen model is > .99 and the out of sample error is always greater than the in sample but with this accuracy it is expected to be very small. Other models were considered for this assignment. For example the nnet package has a multinom function for performing multinomial logistic regression. The nnet package was not as intuitive and I couldn't check the accuracy or use cross validation. Therefore I used the random forest.
